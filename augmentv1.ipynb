{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Script to generate augmented images from given images"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Random augmentations with the following: \n",
    "- Horizontal and vertical flips\n",
    "- Crops\n",
    "- Linear Contrast changing\n",
    "- Gaussian Noise addition\n",
    "- Gaussian Blur\n",
    "- Pixel multiplication (colour change)\n",
    "- Affine transformations: scale, translate, rotate, shear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "Using TensorFlow backend.\n"
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm_notebook, tnrange\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imshow, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers.merge import concatenate, add\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this method takes in the path of the directory containing images and their respective masks, and returns a 4d array with their respective values\n",
    "def get_images_to_augment(path, im_height=256, im_width=256):\n",
    "    # get directory path for unaugmented images\n",
    "    imgs_path = path + \"images_unaugmented\"\n",
    "    print(\"Retrieving images from \" + imgs_path)\n",
    "\n",
    "    # get directory path for unaugmented masks\n",
    "    mask_path = path + \"masks_unaugmented\"\n",
    "    print(\"Retrieving masks from \" + mask_path)\n",
    "    \n",
    "    imgs = os.listdir(imgs_path)\n",
    "    masks = os.listdir(mask_path)\n",
    "\n",
    "    # remove .DS_Store, if it exists in either directory\n",
    "    if \".DS_Store\" in imgs:\n",
    "        imgs.remove('.DS_Store')\n",
    "\n",
    "    if \".DS_Store\" in masks:\n",
    "        masks.remove('.DS_Store')\n",
    "\n",
    "    # remove directory .ipynb_checkpoints if it exists\n",
    "    if \".ipynb_checkpoints\" in imgs:\n",
    "        shutil.rmtree(imgs_path + '/.ipynb_checkpoints')\n",
    "\n",
    "    if \".ipynb_checkpoints\" in masks:\n",
    "        shutil.rmtree(mask_path + '/.ipynb_checkpoints')\n",
    "\n",
    "    # arrays are 4d numpy array of shape (N, height, width, channels)\n",
    "    im_arr = np.zeros((len(imgs), im_height, im_width, 3), dtype=np.uint8)\n",
    "\n",
    "    msk_arr = np.zeros((len(masks), im_height, im_width, 1), dtype=np.uint8)\n",
    "    print('Getting and resizing images ... ')\n",
    "    for n, id_ in tqdm_notebook(enumerate(imgs), total=len(imgs)):\n",
    "        #Load images\n",
    "        img = load_img(imgs_path + '/' + id_)\n",
    "        image = img_to_array(img)\n",
    "        image = resize(image, (256, 256, 3), mode='constant', preserve_range=True)\n",
    "\n",
    "        #Load masks\n",
    "        msk = load_img(mask_path + '/' + id_, color_mode=\"grayscale\")\n",
    "        mask = img_to_array(msk)\n",
    "        mask = resize(mask, (256, 256, 1), mode='constant', preserve_range=True)\n",
    "\n",
    "\n",
    "        im_arr[n] = image\n",
    "        msk_arr[n] = mask\n",
    "    # X now contains the respective values of the pixel intensities in the image\n",
    "    print('Done!')\n",
    "  \n",
    "    return im_arr, msk_arr\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Retrieving images from ./data/duct_test/new_dataset/images_unaugmented\nRetrieving masks from ./data/duct_test/new_dataset/masks_unaugmented\nGetting and resizing images ... \n\nDone!\n(158, 256, 256, 3)\n(158, 256, 256, 1)\n"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "165856298ce54524a6bc6202367c72c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "HBox(children=(IntProgress(value=0, max=158), HTML(value='')))"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#get data \n",
    "#path = './data/test/'\n",
    "path = './data/duct_test/new_dataset/'\n",
    "img_arr, masks_arr = get_images_to_augment(path)\n",
    "print(img_arr.shape)\n",
    "print(masks_arr.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Light augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#light augmentation\n",
    "ia.seed(1)\n",
    "#sequence of random augmentations\n",
    "# Image-specific sequence\n",
    "seq_light_img = iaa.Sequential([\n",
    "    iaa.Fliplr(0.5, random_state=1), # horizontal flips\n",
    "    iaa.Flipud(0.5, random_state=2), # vertical flips\n",
    "    iaa.Crop(percent=(0, 0.1), random_state=3), # random crops\n",
    "    # Small gaussian blur with random sigma between 0 and 0.5.\n",
    "    # But we only blur about 50% of all images.\n",
    "    iaa.Sometimes(0.5,\n",
    "          iaa.GaussianBlur(sigma=(0, 0.5))),\n",
    "\n",
    "    # Strengthen or weaken the contrast in each image.\n",
    "    iaa.contrast.LinearContrast((0.5, 1.25), random_state=4),\n",
    "    # Add gaussian noise for 50% of the images.\n",
    "    # For 50% of all images, we sample the noise once per pixel.\n",
    "    # For the other 50% of all images, we sample the noise per pixel AND\n",
    "    # channel. This can change the color (not only brightness) of the\n",
    "    # pixels.\n",
    "    iaa.Sometimes(0.5, \n",
    "        iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05*255), per_channel=0.5), random_state=5),\n",
    "    # Make some images brighter and some darker.\n",
    "    # In 20% of all cases, we sample the multiplier once per channel,\n",
    "    # which can end up changing the color of the images.\n",
    "    iaa.Multiply((0.8, 1.2), per_channel=0.2, random_state=6),\n",
    "    # Apply affine transformations to each image.\n",
    "    # Scale/zoom them, translate/move them, rotate them and shear them.\n",
    "    iaa.Affine(\n",
    "        scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)}, # random scaling from 80% to 120% of original size\n",
    "        translate_percent={\"x\": (0.0, 0.2), \"y\": (0.0, 0.2)},# translation from 0 translation to 20% of axis size\n",
    "        rotate=(-360, 360), # rotate the image randomly between -360 and 360 degrees\n",
    "        shear=(-45, 45),\n",
    "        cval=255,#set cval to 255 to prevent any black areas occuring \n",
    "        mode='constant', random_state=7\n",
    "    )\n",
    "], random_state=8) # apply augmenters in random order\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask-specific sequence\n",
    "seq_light_mask = iaa.Sequential([\n",
    "    iaa.Fliplr(0.5, random_state=1), # horizontal flips\n",
    "    iaa.Flipud(0.5, random_state=2), # vertical flips\n",
    "    iaa.Crop(percent=(0, 0.1), random_state=3), # random crops\n",
    "    # Small gaussian blur with random sigma between 0 and 0.5.\n",
    "    # But we only blur about 50% of all images.\n",
    "    #iaa.Sometimes(0.5,\n",
    "          #iaa.GaussianBlur(sigma=(0, 0.5))),\n",
    "\n",
    "    # Strengthen or weaken the contrast in each image.\n",
    "    #iaa.contrast.LinearContrast((0.5, 1.25), random_state=4),\n",
    "    # Add gaussian noise for 50% of the images.\n",
    "    # For 50% of all images, we sample the noise once per pixel.\n",
    "    # For the other 50% of all images, we sample the noise per pixel AND\n",
    "    # channel. This can change the color (not only brightness) of the\n",
    "    # pixels.\n",
    "    #iaa.Sometimes(0.5, \n",
    "        #iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05*255), per_channel=0.5), random_state=5),\n",
    "    # Make some images brighter and some darker.\n",
    "    # In 20% of all cases, we sample the multiplier once per channel,\n",
    "    # which can end up changing the color of the images.\n",
    "    #iaa.Multiply((0.8, 1.2), per_channel=0.2, random_state=6),\n",
    "    # Apply affine transformations to each image.\n",
    "    # Scale/zoom them, translate/move them, rotate them and shear them.\n",
    "    iaa.Affine(\n",
    "        scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)}, # random scaling from 80% to 120% of original size\n",
    "        translate_percent={\"x\": (0.0, 0.2), \"y\": (0.0, 0.2)},# translation from 0 translation to 20% of axis size\n",
    "        rotate=(-360, 360), # rotate the image randomly between -360 and 360 degrees\n",
    "        shear=(-45, 45),\n",
    "        cval=255,#set cval to 255 to prevent any black areas occuring \n",
    "        mode='constant', random_state=7\n",
    "    )\n",
    "], random_state=8) # apply augmenters in random order\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "test_img_aug = seq_light_img.augment_image(img_arr[0])\n",
    "test_mask = seq_light_mask.augment_image(masks_arr[0])\n",
    "f, axarr = plt.subplots(1,2)\n",
    "axarr[0].imshow(test_img_aug)\n",
    "axarr[1].imshow(test_mask.reshape(256,256), cmap='gray', vmin=0, vmax=255)\n",
    "#plt.imshow(test_img_aug)\n",
    "#plt.imshow(test_mask.reshape((256,256)), cmap='gray', vmin=0, vmax=255)\n",
    "'''\n",
    "images_aug_light = seq_light_img.augment_images(img_arr)\n",
    "masks_aug_light = seq_light_mask.augment_images(masks_arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "158\n158\n"
    }
   ],
   "source": [
    "#augment the images\n",
    "#for light aug\n",
    "aug_imgs = images_aug_light#images_aug_heavy\n",
    "aug_masks = masks_aug_light#masks_aug_heavy\n",
    "#heavy_augments = augment_images_heavy(img_arr)\n",
    "#print(aug_masks[0].shape)\n",
    "print(len(aug_imgs))\n",
    "print(len(aug_masks))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "aug_masks len: 158\nori_mask_path len: 158\naug_masks2 len: 158\n"
    }
   ],
   "source": [
    "#check if directory to save the files to exists, if not create one\n",
    "aug_img_path = './data/duct_test/new_dataset/augmented_images'\n",
    "aug_mask_path = './data/duct_test/new_dataset/augmented_masks'\n",
    "if not os.path.isdir(aug_img_path):\n",
    "    # if the directory doesnt exist, create the directory\n",
    "    os.mkdir(aug_img_path)\n",
    "else:\n",
    "    # delete the contents of the directory so they can be replaced\n",
    "    imgs_path = aug_img_path + '/*'\n",
    "    imgs_path = glob.glob(imgs_path)\n",
    "    for i in imgs_path:\n",
    "        os.remove(i)\n",
    "\n",
    "if not os.path.isdir(aug_mask_path):\n",
    "    os.mkdir(aug_mask_path)\n",
    "else:\n",
    "    # delete the contents of the directory so they can be replaced\n",
    "    mask_path = aug_mask_path + '/*'\n",
    "    mask_path = glob.glob(mask_path)\n",
    "    for i in mask_path:\n",
    "        os.remove(i)\n",
    "#attain the original filenames\n",
    "ori_imgs = os.listdir('./data/duct_test/new_dataset/images_unaugmented')\n",
    "ori_masks = os.listdir('./data/duct_test/new_dataset/masks_unaugmented')\n",
    "\n",
    "# save the augmented files with the same filenames in the new folder\n",
    "# saving the augmented originals\n",
    "for i in range(len(aug_imgs)):\n",
    "    #use PIL to create an img\n",
    "    augmented = Image.fromarray(aug_imgs[i], 'RGB')\n",
    "    #match it to the corresponding name\n",
    "    img_name = ori_imgs[i]\n",
    "\n",
    "    #save the image to the directory\n",
    "    augmented.save(aug_img_path + '/' + img_name)\n",
    "\n",
    "# saving the augmented masks\n",
    "print(\"aug_masks len: \" + str(len(aug_masks)))\n",
    "print(\"ori_mask_path len: \" + str(len(ori_masks)))\n",
    "aug_masks2 = np.reshape(aug_masks, (len(aug_masks), 256, 256))\n",
    "print(\"aug_masks2 len: \" + str(len(aug_masks2)))\n",
    "for i in range(len(aug_masks)):\n",
    "    augmented = Image.fromarray(aug_masks2[i], 'L')\n",
    "    mask_name = ori_masks[i]\n",
    "    augmented.save(aug_mask_path + '/' + mask_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}